from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_core.runnables import RunnableConfig
from langchain_core.tracers import LangChainTracer
from langchain_core.tracers.run_collector import RunCollectorCallbackHandler
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain.callbacks.base import BaseCallbackHandler
from langchain_core.messages import HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
from langsmith import Client
import streamlit as st
from streamlit_feedback import streamlit_feedback
import time
import os
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

st.set_page_config(page_title="ChatBot with LangSmith", page_icon="ğŸ¤–")
st.title("ğŸ¤–OPENAI API ì±—ë´‡")

# LangSmith í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_ENDPOINT"] = st.secrets["LANGCHAIN_ENDPOINT"]
os.environ["LANGCHAIN_PROJECT"] = st.secrets["LANGCHAIN_PROJECT"]
os.environ["LANGCHAIN_API_KEY"] = st.secrets["LANGCHAIN_API_KEY"]

# LangSmith í´ë¼ì´ì–¸íŠ¸ ë° íŠ¸ë ˆì´ì„œ ì„¤ì •
client = Client()
ls_tracer = LangChainTracer(project_name=os.environ["LANGCHAIN_PROJECT"], client=client)
run_collector = RunCollectorCallbackHandler()
cfg = RunnableConfig()
cfg["callbacks"] = [ls_tracer, run_collector]
cfg["configurable"] = {"session_id": "any"}

class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.markdown(self.text)

# ì±„íŒ… ê¸°ë¡ ì„¤ì •
if "messages" not in st.session_state:
    st.session_state.messages = []

msgs = StreamlitChatMessageHistory(key="langchain_messages")

# ì±„íŒ… ì´ˆê¸°í™” ë²„íŠ¼
reset_history = st.sidebar.button("ì±„íŒ… ì´ˆê¸°í™”")

if reset_history:
    st.session_state.messages = []
    msgs.clear()
    st.session_state["last_run"] = None

# ì±„íŒ…ì´ ë¹„ì–´ìˆìœ¼ë©´ ì´ˆê¸° ë©”ì‹œì§€ ì¶”ê°€
if len(st.session_state.messages) == 0:
    initial_message = AIMessage(content="ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
    st.session_state.messages.append(initial_message)
    msgs.add_ai_message("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for msg in st.session_state.messages:
    st.chat_message(msg.type).write(msg.content)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "í•œê¸€ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{question}"),
    ]
)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input := st.chat_input():
    st.session_state.messages.append(HumanMessage(content=user_input))
    msgs.add_user_message(user_input)
    st.chat_message("human").write(user_input)
    with st.chat_message("ai"):
        stream_handler = StreamHandler(st.empty())
        llm = ChatOpenAI(streaming=True, callbacks=[stream_handler])
        chain = prompt | llm
        chain_with_history = RunnableWithMessageHistory(
            chain,
            lambda session_id: msgs,
            input_messages_key="question",
            history_messages_key="history",
        )
        response = chain_with_history.invoke({"question": user_input}, cfg)
        st.session_state.messages.append(AIMessage(content=response.content))
        msgs.add_ai_message(response.content)
    st.session_state.last_run = run_collector.traced_runs[0].id

# LangSmith ì‹¤í–‰ URL ê°€ì ¸ì˜¤ê¸°
@st.cache_data(ttl="2h", show_spinner=False)
def get_run_url(run_id):
    time.sleep(1)
    return client.read_run(run_id).url

# í”¼ë“œë°± ë° LangSmith ë§í¬ í‘œì‹œ
if st.session_state.get("last_run"):
    run_url = get_run_url(st.session_state.last_run)
    st.sidebar.markdown(f"[LangSmith ì¶”ì ğŸ› ï¸]({run_url})")
    feedback = streamlit_feedback(
        feedback_type="thumbs",
        optional_text_label=None,
        key=f"feedback_{st.session_state.last_run}",
    )
    if feedback:
        scores = {"ğŸ‘": 1, "ğŸ‘": 0}
        client.create_feedback(
            st.session_state.last_run,
            feedback["type"],
            score=scores[feedback["score"]],
            comment=feedback.get("text", None),
        )
        st.toast("í”¼ë“œë°±ì„ ì €ì¥í•˜ì˜€ìŠµë‹ˆë‹¤!", icon="ğŸ“")

# ì‚¬ì´ë“œë°”ì— ì¶”ê°€ ì •ë³´
with st.sidebar:
    "[ì‹ í•œì¹´ë“œ](https://www.shinhancard.com)"
    "[View the source code](https://github.com/jungh5/chat_start/blob/main/Chatbot_log.py)"
    "[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/streamlit/llm-examples?quickstart=1)"