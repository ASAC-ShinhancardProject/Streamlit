import streamlit as st
import anthropic
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langsmith import Client
from streamlit_feedback import streamlit_feedback
import os
from dotenv import load_dotenv
from PyPDF2 import PdfReader
from pathlib import Path
import pandas as pd
from pptx import Presentation
import io
import time  # ì¶”ê°€ëœ ë¶€ë¶„
import docx
import base64
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API í‚¤ ì„¤ì •
openai_api_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")

# OpenAI ì„¤ì •
client = OpenAI(api_key=openai_api_key)

# Streamlit ì•± ì„¤ì •
     # layout="wide" : í˜ì´ì§€ê°€ í™”ë©´ ì „ì²´ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì§€ì •
st.set_page_config(page_title="ì§‘ì½”ê¸°", page_icon="ğŸ¡", layout="wide")


# <head>
# Google Fontsì—ì„œ ì›í•˜ëŠ” í°íŠ¸ ë¡œë“œ
    # í˜„ì¬ëŠ” Black Han Sans, Do Hyeon, Jua ì„¸ ê°€ì§€ í°íŠ¸ë¥¼ ë¡œë“œí•˜ê³  ìˆìŒ (í•œêµ­ì–´ì— ì í•©í•œ í°íŠ¸ì„)

# <style>
    # .custom-titleë¼ëŠ” í´ë˜ìŠ¤ë¥¼ ìƒì„±í•˜ì—¬ í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ì„ ì„¤ì •
        # !important
            # ì´ ì†ì„±ì„ ë‹¤ë¥¸ CSS ê·œì¹™ë³´ë‹¤ ìš°ì„  ì ìš©í•˜ë„ë¡ ì„¤ì •
        # font-family: 'Jua', sans-serif
            # Jua í°íŠ¸ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ , Jua í°íŠ¸ê°€ ì—†ëŠ” í™˜ê²½ì—ì„œëŠ” sans-serif í°íŠ¸ë¥¼ ì‚¬ìš©
        # font-size: 30px
            #  í…ìŠ¤íŠ¸ í¬ê¸°ë¥¼ 30í”½ì…€ë¡œ ì„¤ì •
	    # font-weight: 700
            # í…ìŠ¤íŠ¸ì˜ êµµê¸°ë¥¼ 700(êµµì€ ê¸€ì”¨)ë¡œ ì„¤ì • (ìˆ«ìê°€ ë†’ì„ìˆ˜ë¡ ê¸€ì”¨ê°€ ë” êµµê²Œ í‘œì‹œ)

st.markdown("""
<head>
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Black+Han+Sans&display=swap">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Do+Hyeon&display=swap">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Jua&display=swap">
<style>
.custom-title {
    font-family: 'Jua', sans-serif !important;
    font-size: 30px !important;
    font-weight: 700 !important;
}
.custom-title1 {
    font-family: 'Do Hyeon', sans-serif !important; 
    font-size: 15px !important;
    font-weight: 10% !important;
}

</style>
</head>
""", unsafe_allow_html=True)    # ê¸°ë³¸ì ìœ¼ë¡œ Streamlitì€ ë³´ì•ˆìƒ HTMLì„ í—ˆìš©í•˜ì§€ ì•Šì§€ë§Œ, unsafe_allow_html=True ë¥¼ ì‚¬ìš©í•˜ë©´ HTML íƒœê·¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ


# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ assets í´ë” ê²½ë¡œ ì„¤ì •
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
ASSETS_DIR = os.path.join(SCRIPT_DIR, 'static')

# static í´ë”ì— bot_character.pngì™€ human_character.pngë¼ëŠ” íŒŒì¼ì„ ì €ì¥í–ˆë‹¤ë©´ í•´ë‹¹ ì´ë¯¸ì§€ê°€ ê°ê° ì±—ë´‡ê³¼ ì‚¬ìš©ìì˜ ì•„ë°”íƒ€ ì´ë¯¸ì§€ë¡œ ì‚¬ìš©ë¨
    # 'ì±„íŒ… ê¸°ë¡ì—ì„œ ê°€ì¥ ìµœê·¼ ë©”ì‹œì§€ë§Œ í‘œì‹œ' ì£¼ì„ì„ ì‚´í´ë³´ë©´ avatar="ì±—ë´‡.png"ë¡œ ëª…ì‹œë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ì§€ì •ëœ "ì±—ë´‡.png" íŒŒì¼ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•œë‹¤
    # ì¦‰, í˜„ì¬ ì½”ë“œì—ì„œëŠ” get_avatar_pathë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤
        # ë§¨ ì•„ë˜ì— ì£¼ì„ìœ¼ë¡œ ì½”ë“œë¥¼ ë‹¬ì•„ë†“ê² ìŒ

def get_avatar_path(role: str) -> str:
    """ì´ë¯¸ì§€ íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ë°˜í™˜"""
    image_path = os.path.join(ASSETS_DIR, f'{role}_character.png')
    if os.path.exists(image_path):
        return image_path
    print(f"Warning: Image not found at {image_path}")  # ë””ë²„ê¹…ìš©
    return None

def send_message(message, role, save=True):
    """Display message with appropriate avatar"""
    avatar_path = get_avatar_path('human' if role == 'human' else 'bot')
    try:
        with st.chat_message(role, avatar=avatar_path):             # st.chat_messageë¥¼ ì‚¬ìš©í•´ Streamlitì˜ ëŒ€í™”í˜• ë©”ì‹œì§€ êµ¬ì„± ìš”ì†Œë¡œ ë©”ì‹œì§€ë¥¼ ì¶œë ¥
            st.markdown(message, unsafe_allow_html=True)
        if save:  # ë©”ì‹œì§€ë¥¼ í•œ ë²ˆë§Œ ì €ì¥
            save_message(message, role)
    except Exception as e:
        print(f"Error displaying message with avatar: {e}")
        with st.chat_message(role):
            st.markdown(message, unsafe_allow_html=True)
        if save:
            save_message(message, role)

def get_image_as_base64(image_path):
    """ì´ë¯¸ì§€ë¥¼ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜"""
    try:
        with open(image_path, "rb") as img_file:
            return base64.b64encode(img_file.read()).decode("utf-8")
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""
    

# ë°°ê²½ ì´ë¯¸ì§€ ì¶”ê°€
bg_image_path = "static/bg.png"  # ë°°ê²½ ì´ë¯¸ì§€ ê²½ë¡œ

# <style>
# background-size: cover;
    # ì´ë¯¸ì§€ë¥¼ í™”ë©´ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
# background-attachment: fixed;
    # ìŠ¤í¬ë¡¤ì„ í•´ë„ ë°°ê²½ ì´ë¯¸ì§€ê°€ ê³ ì •ë˜ì–´ ì›€ì§ì´ì§€ ì•ŠìŒ
# background-repeat: no-repeat;
    # ì´ë¯¸ì§€ë¥¼ ë°˜ë³µí•˜ì§€ ì•ŠìŒ

#  data-testid = 
    # Streamlit ì»´í¬ë„ŒíŠ¸ë¥¼ ì„ íƒí•˜ëŠ” ë° ì‚¬ìš©
# .stMain:
	# Streamlit ì•±ì˜ ì£¼ìš” ì½˜í…ì¸  ì˜ì—­ì„ ì„ íƒ

if Path(bg_image_path).exists():
    bg_image_base64 = get_image_as_base64(bg_image_path)
    st.markdown(
        f"""
        <style>
        /* ì „ì²´ í˜ì´ì§€ ë°°ê²½ */
        html {{
            background-image: url("data:image/png;base64,{bg_image_base64}");
            background-size: cover; 
            background-attachment: fixed;
            background-repeat: no-repeat;
        }}

        /* í…ìŠ¤íŠ¸ ì…ë ¥ì°½ í•˜ë‹¨ ì˜ì—­ (stChatInput) */
        [data-testid="stApp"]{{
            background-image: url("data:image/png;base64,{bg_image_base64}");
            background-size: cover;
    /       background: rgba(255, 255, 255, 0); /* íˆ¬ëª…í™” *
        }}
        
        /* ì‚¬ì´ë“œë°” ë°°ê²½ íˆ¬ëª…í™” */
        [data-testid="stSidebar"] {{
            background: rgba(255, 255, 255, 0); /* íˆ¬ëª…í™” */
        }}
        
        /* ì‚¬ì´ë“œë°” ë°°ê²½ íˆ¬ëª…í™” */
        [data-testid="stHeader"] {{
            background: rgba(255, 255, 255, 0); /* íˆ¬ëª…í™” */
        }}
        
        /* ì‚¬ì´ë“œë°” ë°°ê²½ íˆ¬ëª…í™” */
        [data-testid="stBottom"] {{
            background: rgba(255, 255, 255, 0); /* íˆ¬ëª…í™” */
        }}
        
        /* ì‚¬ì´ë“œë°” ë°°ê²½ íˆ¬ëª…í™” */
        [data-testid="stBottom"] > div {{
            background: rgba(255, 255, 255, 0); /* íˆ¬ëª…í™” */
        }}
        
        /*íŠ¹ì • ì˜ì—­ ìƒ‰ìƒ ë³€ê²½ */
        .stMain {{
            background: rgba(255, 255, 255, 255); /* íˆ¬ëª…í™” */
        }}
        """,
        unsafe_allow_html=True
    )
else:
    st.warning("ë°°ê²½ ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")



# í˜ì´ì§€ ì œëª©
st.markdown('<h1 class="custom-title">ğŸ¡ ì§‘ì½”ê¸°</h1>', unsafe_allow_html=True)
#st.markdown('<h3 class="custom-title1"> ì•„íŒŒíŠ¸ì— ê´€í•´ ë¬¼ì–´ë³´ì„¸ìš” (ì•„íŒŒíŠ¸ ì •ë³´, ì²­ì•½, ëŒ€ì¶œ, ì„¸ê¸ˆ ë“±) </h3>', unsafe_allow_html=True)


if not openai_api_key:
    st.error("OpenAI API key ì„¤ì •ì„ í™•ì¸í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.")
    st.stop()

# í”„ë¡¬í”„íŠ¸
content_chatbot="ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë¶€ë™ì‚° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì—ê²Œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠ” ë°©ì‹ìœ¼ë¡œ ì„¤ëª…í•˜ë©°, \
                ì „ë¬¸ì„±ì„ ê°€ì§€ê³ , í•­ìƒ ì¹œì ˆí•œ ì–´ì¡°ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤. boldì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„± ì¢‹ê²Œ ëŒ€ë‹µí•©ë‹ˆë‹¤.\
                ì •ë³´ëŠ” ì œê³µëœ ë¬¸ì„œì™€ ë¡œì»¬í™˜ê²½ì—ì„œ ì°¾ì•„ì˜¤ë©° ì¶œì²˜ë¥¼ ì •í™•í•˜ê²Œ í‘œì‹œí•©ë‹ˆë‹¤.\
                Mark the source, including the link from the source, at the end of the information you find. \
                If you find the info from the uploaded document, mark it as (í•™ìŠµë¬¸ì„œ)\
                ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì˜ ë‹¤ìŒ ë¶€ë¶„ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. \
                ë‹µì„ ëª¨ë¥´ëŠ” ê²½ìš° ëª¨ë¥¸ë‹¤ê³  ë§í•˜ì„¸ìš”. \
                ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ê²½ìš° ë¬¸ë‹¨ êµ¬ë¶„ì„ ì˜ í•´ì•¼í•©ë‹ˆë‹¤.\
                ëŒ€ë‹µì´ ê¸¸ì–´ì§ˆ ê²½ìš° ì¤„ë°”ê¿ˆì„ í†µí•´ ê°€ë…ì„±ì„ ë†’ì…ë‹ˆë‹¤. ì´ì „ì˜ ëŒ€í™” ë‚´ìš©ì„ ì˜ ê¸°ì–µí•˜ì—¬ ëŒ€í™” ë§¥ë½ì„ íŒŒì•…í•©ë‹ˆë‹¤."

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    # ì„¸ì…˜ ìƒíƒœê°€ ì²˜ìŒ ì„¤ì •ë  ë•Œë§Œ ì´ ì½”ë“œê°€ ì‹¤í–‰ëœë‹¤
    # ì´ë¯¸ ì´ˆê¸°í™”ëœ ì„¸ì…˜ì— ëŒ€í•´ ë‹¤ì‹œ ì´ˆê¸°í™”í•˜ì§€ ì•Šë„ë¡ ì„¤ì •
if 'initialized' not in st.session_state:
    st.session_state.file_qa_messages = [SystemMessage(content = content_chatbot)]  # file_qa_messages : ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ë³€ìˆ˜ / ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ëŒ€í™” ë©”ì„¸ì§€ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì €ì¥
                                                                                    # SystemMessage(content=content_chatbot) : content_chatbot ë³€ìˆ˜ì— ì €ì¥ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ˆê¸° ë©”ì‹œì§€ë¥¼ ì„¤ì •
    st.session_state.file_qa_content = None     # ì—…ë¡œë“œëœ íŒŒì¼ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ ë³€ìˆ˜ / ì´ˆê¸°ê°’ì€ Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŒì„ ë‚˜íƒ€ëƒ„
    st.session_state.file_qa_data = None        # ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ ë³€í™˜ëœ êµ¬ì¡°í™”ëœ ë°ì´í„°(ì˜ˆ: pandas DataFrame)ë¥¼ ì €ì¥í•˜ëŠ” ë³€ìˆ˜ / PDF, Word, Excel ë“±ì˜ íŒŒì¼ì„ ì—…ë¡œë“œí•œ í›„ ì´ë¥¼ ì²˜ë¦¬í•œ ê²°ê³¼ê°€ ì—¬ê¸°ì— ì €ì¥ë¨
    st.session_state.initialized = True         # ì„¸ì…˜ ìƒíƒœê°€ ì´ˆê¸°í™”ë˜ì—ˆìŒì„ ë‚˜íƒ€ë‚´ëŠ” í”Œë˜ê·¸ / Streamlitì€ ê¸°ë³¸ì ìœ¼ë¡œ í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•  ë•Œë§ˆë‹¤ ì½”ë“œë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì§€ë§Œ í•´ë‹¹ ì˜µì…˜ì„ Trueë¡œ ì‚¬ì˜¹í•˜ë©´ ìƒíƒœë¥¼ ìœ ì§€í•¨
    st.session_state.greeting_displayed = False  # ì¸ì‚¬ í‘œì‹œ ì—¬ë¶€ë¥¼ ì¶”ì í•˜ëŠ” ìƒˆë¡œìš´ ë³€ìˆ˜ / ì•±ì´ ì²˜ìŒ ì‹¤í–‰ë˜ì—ˆì„ ë•Œ, ì±—ë´‡ì´ ì‚¬ìš©ìì—ê²Œ ì¸ì‚¬ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•˜ë„ë¡ ì„¤ì •


# ì‚¬ì´ë“œë°”ì— íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯ ì¶”ê°€
with st.sidebar:
    st.markdown("**[ë§Œë“ ì‚¬ëŒ]** ì´ì¼ì„­ ì—°ì§± ì´ë¦¬ ë„í•‘ ìª¼ë§")    # **ë§Œë“  ì‚¬ëŒ**ì„ êµµê²Œ í‘œì‹œ
    #st.markdown("File Upload (Optional)")
    uploaded_file = st.file_uploader("Upload a file", type=("docx", "pdf", "csv", "xlsx", "pptx"))  # Streamlitì—ì„œ ì œê³µí•˜ëŠ” íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯
    if uploaded_file:
        st.success(f"File '{uploaded_file.name}' uploaded successfully.")

# ì±„íŒ… ì´ˆê¸°í™” ë²„íŠ¼
reset_history = st.sidebar.button("ì±„íŒ… ì´ˆê¸°í™”")

if reset_history:
    st.session_state.file_qa_messages = []      # ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” ì„¸ì…˜ ë³€ìˆ˜ë¥¼ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”í•˜ì—¬ ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ì„ ì‚­ì œí•¨
    st.session_state.file_qa_content = None     # ì—…ë¡œë“œëœ íŒŒì¼ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ë³€ìˆ˜ë¥¼ Noneìœ¼ë¡œ ì´ˆê¸°í™”í•˜ì—¬ ì—…ë¡œë“œëœ íŒŒì¼ ë‚´ìš©ì„ ì‚­ì œí•¨
    st.session_state.greeting_displayed = False  # ì´ˆê¸°í™” ì‹œ ì¸ì‚¬ í‘œì‹œ ìƒíƒœë„ ì´ˆê¸°í™” / ë°‘ì—ì„œ ì¸ì‚¬ ë©”ì‹œì§€ ìƒì„± í›„ Trueë¡œ ë°”ë€œ
### ì—…ë¡œë“œëœ íŒŒì¼ í¬ê¸° ì œí•œì„ ì¶”ê°€í•˜ê±°ë‚˜ íŒŒì¼ì´ ë„ˆë¬´ í´ ê²½ìš° ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œë¥¼ í•˜ëŠ” ê±´ ì–´ë–¨ê¹Œ???


# íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜
def process_file(file):
    if file is None:
        return None, None
    try:
        # í…ìŠ¤íŠ¸ íŒŒì¼ ë‚´ìš©ì„ UTF-8 ë””ì½”ë”©í•˜ì—¬ í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ ë³€í™˜
        if file.type == "text/plain":
            content = file.read().decode()
            return content, None
        
        # PyPDF2ì˜ PdfReaderë¥¼ ì‚¬ìš©í•˜ì—¬ PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ / ê° í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì½ì–´ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë³‘í•©
        elif file.type == "application/pdf":
            pdf_reader = PdfReader(io.BytesIO(file.read()))
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            return text, None
        
        # pandasì˜ read_csvë¥¼ ì‚¬ìš©í•˜ì—¬ CSV ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë¡œë“œ / í…ìŠ¤íŠ¸ë¡œ ë³´ê¸° ìœ„í•´ DataFrameì„ ë¬¸ìì—´ë¡œ ë³€í™˜(df.to_string()) / ë°ì´í„°ì™€ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ëª¨ë‘ ë°˜í™˜
        elif file.type == "text/csv":
            df = pd.read_csv(file)
            return df.to_string(), df
        
        # CSVì™€ ë™ì¼í•˜ê²Œ í…ìŠ¤íŠ¸ì™€ ë°ì´í„° ë‘˜ ë‹¤ ë°˜í™˜ / pandasì˜ read_excel ì‚¬ìš©
            # sheetëŠ” ë°˜ë“œì‹œ í•˜ë‚˜ì—¬ë§Œ í•˜ëŠ” ë“¯?
        elif file.type == "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet":
            df = pd.read_excel(file)
            return df.to_string(), df
        
        # python-pptxì˜ Presentation ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¬ë¼ì´ë“œ í…ìŠ¤íŠ¸ ì¶”ì¶œ / ê° ìŠ¬ë¼ì´ë“œì˜ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë³‘í•©
        elif file.type == "application/vnd.openxmlformats-officedocument.presentationml.presentation":
            prs = Presentation(file)
            text = ""
            for slide in prs.slides:
                for shape in slide.shapes:
                    if hasattr(shape, 'text'):
                        text += shape.text + "\n"
            return text, None
        
        # python-docxë¥¼ ì‚¬ìš©í•˜ì—¬ Word íŒŒì¼ ë‚´ìš©ì„ ì¶”ì¶œ / ê° ë¬¸ë‹¨ì˜ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë³‘í•©
        elif file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":  # ì¶”ê°€ëœ ë¶€ë¶„
            doc = docx.Document(file)
            text = ""
            for para in doc.paragraphs:
                text += para.text + "\n"
            return text, None
        
        # ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì˜ ê²½ìš° ì˜¤ë¥˜ ë©”ì„¸ì§€ì™€ None ë°˜í™˜
        else:
            return f"Unsupported file type: {file.type}", None
    except Exception as e:
        st.error(f"Error processing file: {str(e)}")
        return None, None
    

# íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬
if uploaded_file:
    with st.spinner("Processing uploaded file..."):
        st.session_state.file_qa_content, st.session_state.file_qa_data = process_file(uploaded_file)
        if st.session_state.file_qa_content:
            st.sidebar.success(f"File '{uploaded_file.name}' processed successfully.")
        else:
            st.sidebar.error("Failed to process the file.")

# ì±—ë´‡ ì‘ë‹µ í•¨ìˆ˜
def get_chatbot_response(prompt, file_content=None):
    try:
        messages = [
            {"role": "system", "content": content_chatbot},     # content_chatbot í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•´ ì±—ë´‡ì˜ ì—­í• ê³¼ ì‘ë‹µ ìŠ¤íƒ€ì¼ì„ ì •ì˜
            {"role": "user", "content": prompt}     # prompt : ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ ë˜ëŠ” ìš”ì²­
        ]

        response = client.chat.completions.create(      # client.chat.completions.create : OpenAI GPT ëª¨ë¸ì„ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜
            model="gpt-4o-mini",        # ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
            messages=messages,
            max_tokens=3200,            # ëª¨ë¸ì´ ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜ / GPT-4o-miniì˜ ìµœëŒ€ í† í° ìˆ˜ëŠ” 4096ì¼ ê°€ëŠ¥ì„± (í™•ì¸ í•„ìš”)
        )

        response_text = response.choices[0].message.content     # ì²«ë²ˆì§¸ ì‘ë‹µ(choices[0])ì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš©(message.content)ì„ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
        return response_text
    except Exception as e:
        st.error(f"Error in chatbot response: {str(e)}")
        return None

# ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í•¨ìˆ˜
    # ì‚¬ìš©ìê°€ í…ìŠ¤íŠ¸ê°€ ìƒì„±ë˜ëŠ” ê²ƒì²˜ëŸ¼ ëŠë‚„ ìˆ˜ ìˆëŠ” ì‹œê°ì  íš¨ê³¼ë¥¼ ì œê³µ
def stream_response(response_text, response_container):
    response = ""       # í‘œì‹œë  ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  ë³€ìˆ˜ë¥¼ ì´ˆê¸°í™”
    for char in response_text:
        response += char    # í˜„ì¬ ë¬¸ìë¥¼ ê¸°ì¡´ ì‘ë‹µ í…ìŠ¤íŠ¸ì— ì¶”ê°€ / í•œ ê¸€ì ì”©
        response_container.markdown(response, unsafe_allow_html=True)
        time.sleep(0.01)    # ê° ë¬¸ìë¥¼ í‘œì‹œí•˜ê¸° ì „ì— ì•½ê°„ì˜ ì§€ì—°(0.01ì´ˆ)ì„ ì¶”ê°€



# ì‚¬ì´ë“œë°”ì—ì„œ í…ìŠ¤íŠ¸ ë¶„ì„ ì±—ë´‡ ëª¨ë“œ ì¶”ê°€
def create_sidebar_with_text_analysis():
    """ì‚¬ì´ë“œë°”ì—ì„œ í…ìŠ¤íŠ¸ ë¶„ì„ ì±—ë´‡ ëª¨ë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
    with st.sidebar:
        st.markdown("### ğŸ¤– ì±—ë´‡ ëª¨ë“œ ì„ íƒ")
        
        # ëª¨ë“œ ì„ íƒ
        mode = st.radio(
            "ì›í•˜ì‹œëŠ” ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:",
            ["ë¶€ë™ì‚° ì¸ì‚¬ì´íŠ¸", "ë¶€ë™ì‚° ì •ì±…/ê¸ˆìœµ"],        # ê¸°ë³¸ì ìœ¼ë¡œ 'ë¶€ë™ì‚° ì¸ì‚¬ì´íŠ¸'ê°€ ì„ íƒëœë‹¤ / í˜„ì¬ í•´ë‹¹ ê¸°ëŠ¥ì„ í™”ë©´ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ë‹¤ (í™•ì¸ í•„ìš”)
            index=0,
            key="chat_mode_sidebar"  # ê³ ìœ  í‚¤ë¡œ ë³€ê²½
        )
        
        # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
        st.session_state.analysis_mode = (mode == "í…ìŠ¤íŠ¸ ë¶„ì„ ì±—ë´‡")

# ì¸ì‚¬ ë©”ì‹œì§€ í‘œì‹œ (ì±—ë´‡ì´ ë¨¼ì € ì¸ì‚¬)
if not st.session_state.greeting_displayed:
    initial_message = AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”. ì•„íŒŒíŠ¸ ì‹œì¥ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš” ğŸ˜Š  \n"
                                        "ë‚´ ì§‘ ë§ˆë ¨ê³¼ ì‹œì¥ ì •ë³´ì— ëŒ€í•œ ì§ˆë¬¸ ë° ë‹µë³€ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤")
    st.session_state.file_qa_messages.append(initial_message)       # file_qa_messages ë¦¬ìŠ¤íŠ¸ëŠ” ëŒ€í™” ë©”ì‹œì§€ë¥¼ ì €ì¥í•˜ëŠ” ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ / ìƒì„±í•œ ì´ˆê¸° ë©”ì‹œì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ì—¬ ì €ì¥
    st.session_state.greeting_displayed = True  # ì¸ì‚¬ë¥¼ í‘œì‹œí–ˆìŒì„ ê¸°ë¡


# ì±„íŒ… ê¸°ë¡ì—ì„œ ê°€ì¥ ìµœê·¼ ë©”ì‹œì§€ë§Œ í‘œì‹œ
if st.session_state.file_qa_messages:   # ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆì§€ ì•Šë‹¤ë©´ ê°€ì¥ ìµœê·¼ ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì˜´
    last_message = st.session_state.file_qa_messages[-1]    # ë¦¬ìŠ¤íŠ¸ì˜ ë§ˆì§€ë§‰ ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì˜´
    if isinstance(last_message, AIMessage):     # ê°€ì ¸ì˜¨ ë©”ì‹œì§€ê°€ ì±—ë´‡ ë©”ì‹œì§€ì¸ì§€, ì‚¬ìš©ì ë©”ì‹œì§€ì¸ì§€ í™•ì¸
        st.chat_message("ai", avatar="ì±—ë´‡.png").write(last_message.content)
    elif isinstance(last_message, HumanMessage):
        st.chat_message("human", avatar="ì§ˆë¬¸.png").write(last_message.content)


# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë¶€ë™ì‚° ì‹œì¥ì— ê´€í•´ ë¬¼ì–´ë³´ì„¸ìš”"):        # ì‚¬ìš©ìë¡œë¶€í„° ì…ë ¥ì„ ë°›ëŠ” Streamlitì˜ ì…ë ¥ ìœ„ì ¯ / ê´„í˜¸ ì•ˆì—ëŠ” ì•ˆë‚´ë¬¸
    # ì‚¬ìš©ì ì§ˆë¬¸ ë©”ì‹œì§€ ì¶œë ¥ ë° ì €ì¥
    with st.chat_message("human", avatar="ì§ˆë¬¸.png"):         # ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œ / ì‚¬ìš©ìì˜ ì•„ë°”íƒ€ ì´ë¯¸ì§€ ì„¤ì •
        formatted_prompt = prompt.replace("\n", "<br>")      # ì…ë ¥ëœ ë©”ì‹œì§€ì—ì„œ ì¤„ë°”ê¿ˆ(\n)ì„ HTMLì˜ <br> íƒœê·¸ë¡œ ëŒ€ì²´í•˜ì—¬ ì›¹ í™”ë©´ì—ì„œ ì˜¬ë°”ë¥´ê²Œ ì¤„ë°”ê¿ˆì´ í‘œì‹œë˜ë„ë¡ ì²˜ë¦¬
        st.markdown(f'<div class="user-message">{formatted_prompt}</div>', unsafe_allow_html=True)  # st.markdownì„ ì‚¬ìš©í•´ í¬ë§·ëœ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ HTML í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
    st.session_state.file_qa_messages.append(HumanMessage(content=prompt))      # HumanMessage(content=prompt)ë¥¼ ìƒì„±í•˜ì—¬ ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡(file_qa_messages)ì— ì¶”ê°€

    # ìƒˆë¡œìš´ ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±
    with st.chat_message("ai", avatar="ì±—ë´‡.png"):
        response_container = st.empty()  # ì—¬ê¸°ì„œ ìƒˆë¡œìš´ ë¹ˆ ì»¨í…Œì´ë„ˆ ìƒì„±
        with st.spinner("ë‹µë³€ìƒì„±ì¤‘..."):       # ì±—ë´‡ ì‘ë‹µ ìƒì„± ì¤‘ì„ì„ ì‚¬ìš©ìì—ê²Œ í‘œì‹œí•˜ëŠ” ìŠ¤í”¼ë„ˆ UI
            response = get_chatbot_response(prompt, st.session_state.file_qa_content)       # prompt(ì‚¬ìš©ì ì…ë ¥)ì™€ st.session_state.file_qa_content(ì—…ë¡œë“œëœ íŒŒì¼ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°)ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì±—ë´‡ ì‘ë‹µì„ ìƒì„±

            if response:
                st.session_state.file_qa_messages.append(AIMessage(content=response))       # ì±—ë´‡ì˜ ì‘ë‹µ ë©”ì‹œì§€ë¥¼ AIMessage ê°ì²´ë¡œ ìƒì„±í•˜ì—¬ ëŒ€í™” ê¸°ë¡(file_qa_messages)ì— ì¶”ê°€
                stream_response(response, response_container)  # ì—¬ê¸°ì„œ response_containerë¥¼ ì¸ìë¡œ ì „ë‹¬ / ì±—ë´‡ ì‘ë‹µì„ ê¸€ì ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì¶œë ¥
            else:
                response_container.error("Failed to get a response. Please try again.")     # ì‘ë‹µì— ì‹¤íŒ¨í•œ ê²½ìš° ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥



# í”¼ë“œë°± ìˆ˜ì§‘
if len(st.session_state.file_qa_messages) > 1:
    last_message = st.session_state.file_qa_messages[-1]
    if isinstance(last_message, AIMessage):
        feedback = streamlit_feedback(
            feedback_type="thumbs",
            key=f"file_qa_feedback_{len(st.session_state.file_qa_messages)}"
        )
        if feedback:
            score = 1 if feedback["score"] == "thumbsup" else 0
            client = Client()
            run_id = client.create_run(
                project_name=os.getenv("LANGCHAIN_PROJECT"),
                name="File Q&A Interaction",
                inputs={"messages": [msg.content for msg in st.session_state.file_qa_messages[1:]]},
            ).id
            client.create_feedback(run_id, "user_score", score=score)
            st.toast("Feedback submitted!", icon="âœ…")





# get_avatar_pathë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì•„ë˜ ì½”ë“œ ì°¸ê³ 

# if st.session_state.file_qa_messages:
#     last_message = st.session_state.file_qa_messages[-1]
#     if isinstance(last_message, AIMessage):
#         avatar_path = get_avatar_path('bot')  # bot_character.png ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
#         st.chat_message("ai", avatar=avatar_path).write(last_message.content)
#     elif isinstance(last_message, HumanMessage):
#         avatar_path = get_avatar_path('human')  # human_character.png ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
#         st.chat_message("human", avatar=avatar_path).write(last_message.content)



# # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
# if prompt := st.chat_input("ë¶€ë™ì‚° ì‹œì¥ì— ê´€í•´ ë¬¼ì–´ë³´ì„¸ìš”"):
#     # ì‚¬ìš©ì ì§ˆë¬¸ ë©”ì‹œì§€ ì¶œë ¥ ë° ì €ì¥
#     with st.chat_message("human", avatar=get_avatar_path("human")):
#         formatted_prompt = prompt.replace("\n", "<br>")
#         st.markdown(f'<div class="user-message">{formatted_prompt}</div>', unsafe_allow_html=True)
#     st.session_state.file_qa_messages.append(HumanMessage(content=prompt))

#     # ìƒˆë¡œìš´ ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±
#     with st.chat_message("ai", avatar=get_avatar_path("bot")):
#         response_container = st.empty()
#         with st.spinner("ë‹µë³€ìƒì„±ì¤‘..."):
#             response = get_chatbot_response(prompt, st.session_state.file_qa_content)

#             if response:
#                 st.session_state.file_qa_messages.append(AIMessage(content=response))
#                 stream_response(response, response_container)
#             else:
#                 response_container.error("Failed to get a response. Please try again.")